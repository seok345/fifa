import torch
import pandas as pd
import numpy as np
from transformers import MobileBertForSequenceClassification, MobileBertTokenizer
from tqdm import tqdm

# ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# Îç∞Ïù¥ÌÑ∞ Î°úÎî©
data_path = "fifa_cleaned.csv"  # Ï†ÑÏ≤òÎ¶¨Îêú FIFA Î¶¨Î∑∞ CSV (Ïòà: 10Ïûê Ïù¥ÏÉÅ, Ï§ëÎ¶ΩÏ†êÏàò Ï†úÍ±∞ Îì±)
df = pd.read_csv(data_path, encoding="utf-8-sig")

# Í∞êÏ†ï ÎùºÎ≤® ÏÉùÏÑ± (1~2Ï†ê -> 0, 4~5Ï†ê -> 1) / 3Ï†ê Ï†úÍ±∞
df = df[df['score'] != 3]
df['Sentiment'] = df['score'].apply(lambda x: 0 if x <= 2 else 1)

# ÏûÖÎ†• ÌÖçÏä§Ìä∏ÏôÄ ÎùºÎ≤® Î∂ÑÎ¶¨
data_X = df['content'].astype(str).tolist()
labels = df['Sentiment'].astype(int).values

print("Î¶¨Î∑∞ ÏÉòÌîå Í∞úÏàò:", len(data_X))
print("Í∞êÏÑ± ÎùºÎ≤® ÏÉòÌîå:", labels[:5])

# ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎî© Î∞è ÌÜ†ÌÅ∞Ìôî
tokenizer = MobileBertTokenizer.from_pretrained("mobilebert_fifa_model")
inputs = tokenizer(data_X, truncation=True, max_length=256, padding="max_length", return_tensors="pt")
input_ids = inputs['input_ids']
attention_mask = inputs['attention_mask']
print("‚úÖ ÌÜ†ÌÅ∞Ìôî ÏôÑÎ£å")

# DataLoader ÏÉùÏÑ±
batch_size = 8
test_inputs = input_ids
test_labels = torch.tensor(labels).long()
test_masks = attention_mask
test_data = torch.utils.data.TensorDataset(test_inputs, test_masks, test_labels)
test_sampler = torch.utils.data.SequentialSampler(test_data)
test_dataloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)
print("‚úÖ DataLoader Íµ¨Ï∂ï ÏôÑÎ£å")

# Î™®Îç∏ Î°úÎî©
model = MobileBertForSequenceClassification.from_pretrained("mobilebert_fifa_model")
model.to(device)
model.eval()

# ÏòàÏ∏° ÏàòÌñâ
test_pred = []
test_true = []

for batch in tqdm(test_dataloader, desc="Evaluating"):
    batch_ids, batch_mask, batch_labels = [b.to(device) for b in batch]

    with torch.no_grad():
        outputs = model(batch_ids, attention_mask=batch_mask)
    logits = outputs.logits
    preds = torch.argmax(logits, dim=1)

    test_pred.extend(preds.cpu().numpy())
    test_true.extend(batch_labels.cpu().numpy())

# Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞
test_accuracy = np.mean(np.array(test_pred) == np.array(test_true))
print(f"\nüéØ Ï†ÑÏ≤¥ FIFA Î¶¨Î∑∞ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú Î∂ÑÎ•ò Ï†ïÌôïÎèÑ: {test_accuracy:.4f}")
